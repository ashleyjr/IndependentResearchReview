\documentclass[journal]{IEEEtran}
\usepackage{cite}




 \usepackage[pdftex]{graphicx}



\begin{document}
\title{Effective Tumor Classification Exploiting Volumetric Image Analysis}
\author{Ashley J. Robinson}

% The paper headers
\markboth{Southampton University, Department of Electronics and Computer Science, Independent Research Review.}%
{Robinson: Effective Tumor Classification Exploiting Volumetric Image Analysis}

\maketitle


\begin{abstract}

\dots

\end{abstract}







\begin{IEEEkeywords}
Tumor, Classification
\end{IEEEkeywords}



\IEEEpeerreviewmaketitle







\section{Introduction}
\IEEEPARstart{T}{his} research review covers the use of volumetric image analysis in medicine to accurately classify tumors. 
The problem is to be approached by considering only the general case where no specific area of the human body is considered.
Rather than trying to classify lung or brain tumors individually the goal is to consider what tumors have in common and given an entire image of a human body is it possible to classify tumors in any given section?
The motivation behind this is to make the most of medical scanning.
Dosages of radiation, cost and simply the time required are all reasons to reduce the number of scans needed, making the most of any data gathered is a constructive method of scan frequency reduction.
The objective is to provide a recommendation for a system to be implemented such that a medical practitioner could use it as a tool for diagnosis.  

The architecture in Fig.~\ref{fig:Proposed} is a simplistic view of the system to be recommended; inspired by those discussed in ~\cite{ahmed2011efficacy,kumar2011classification,sachdeva2011multiclass}.
A chain of stages leads from raw data gathered from the patient to a diagnosis from a classification algorithm.
A confidence sub-block enables the domain expert to view the performance of the entire system without knowing the intricacies of operation; this requires processing to be explained with respect to their domain.
Raw data is captured from the patient and passed to system for pre-processing then feature extraction.
Input patterns are produced from volumetric feature extraction dependent on a pre-determined list of known useful features. 
Feature reduction and normalisation is then used frame the data as such to make the most of the classification algorithm used to provide support for diagnosis.

\begin{figure}[!htb]
   \centering
   \includegraphics[width = 0.4\textwidth]{Figures/Proposed.pdf}
   \label{fig:Proposed}
   \caption{Proposed system architecture.}
\end{figure}











\section{Image Acquisition}
\label{sec:image}

A standard X-ray medical scan is tuned to produce and image of human bone.
The rays are attenuated by different materials in the body, more so by dense regions of bone, and the image is gained from this attenuation effect.  
This uses a single source and substrate to capture the image.
Taking multiple images from many different angles gathers more information and a 3D image can be made by stitching these together.
Fig.~\ref{fig:ct} describes the physical process of gathering data to be used in Computed Tomography (CT).
A ring allows images to be capture from 360$^{\circ}$ in a single plane then by moving in the orthogonal plane, in Fig.~\ref{fig:ct} through the paper, a full volumetric image of the patient can be made. 

\begin{figure}[!htb]
   \centering
   \includegraphics[width = 0.15\textwidth]{Figures/CT.pdf}
   \label{fig:ct}
   \caption{Acquiring data from Computed Tomography. Adapted from~\cite{kayvan2006biomedical}.}
\end{figure}

Any method of non-invasive image capturing in 2D can therefore by expanded to work in 3D by using the CT principle.
Different methods have trade offs such as radiation dosages and resolution.
Ultrasound is a method of image acquisition with the advantage of small processing overhead allowing an internal organs to be view in real-time. 
It can be used for CT but higher resolution methods are favoured such as X-ray and Magnetic Resonance Imaging.

There are also other non-intrusive methods that do not use electromagnetic or ultrasonic waves.
Hand palpitation is a common technique used by medical practitioners to gain an impression of abnormalities near the surface of the human body. 
Electromechanical apparatus employing the same technique can be used transfer the dimension of a growth to a volumetric image~\cite{liu09haptic,wellman1997modeling}.  
This offers far less data for analysis.

Data is typically stored as a series of grayscale 2D images which are slices of the scan.
The image viewer will build 3D images as and when required using these slices.
The common medical standard for these images is DICOM which holds the relationships between slices and also patient information~\cite{dicom11nema}.
Viewing the data naturally proves problematic because it is 3D data shown in an isometric fashion on a 2D screen.
Viewing software provides interactive images as shown in Fig.~\ref{fig:3d} which allows the user to move three slices to concentrate on corner on specific points.

\begin{figure}[!htb]
   \centering
   \includegraphics[width = 0.4\textwidth]{Figures/3Dview.png}
   \label{fig:3d}
   \caption{An MRI scan of a healthy brain taken from~\cite{cia} and rendered by~\cite{slicer}.}
\end{figure}

The analogue of a pixel (picture element) in 2D image is called a voxel (volumetric element) in a 3D image.
This is exactly the same idea but with a extra dimension to form a cube~\cite{lohmann1998volumetric}.
They can be considered cubes but also points which may make visualisation and processing easier to understand.










\section{Pre-processing}
\label{sec:pre}

The provided raw data needs to be converted from the format delivered by the acquisition technology to a three dimensional matrix ready for generic processing.
Removal of watermarking, which may have been inserted for human review, should also be removed at this stage. 
This is trivial in theory but requires a database of artifacts or manual review to accomplish.
There are also techniques, not considered in this paper, which can be applied just to the slices of a volumetric image which may be used to reduce processing overheads~\cite{harauz86exact}.

Filters can be used to enhance the quality of images.
These are split two categories, linear and non-linear~\cite{lohmann1998volumetric}.
Linear filtering is achieved by using a mask to weight each voxel the surrounding voxels.
This is done with a weighted mask which is applied to image in path which covers all regions.


\subsection{Histogram Operations}

An image histogram is a simple yet powerful tool which is a mapping from the image to a 2D plot of the frequency of intensity.
This contains information on the type of material seen in the image, if it can be determined from intensity, and how much of that material is used to form the entire image.
Image enhancement can be performed using point operations with information from the histogram.
Normalisation stretches the histogram to cover all available values of intensity therefore improving contrast.
Equalisation attempts to flatten the histogram by distributing intensity~\cite{nixon02feature}.


\subsection{Spatial Filtering}
Spatial filters use the neighbourhood of voxels to create a new value for each voxel in an image. 
An original image $I(u,v,w)$ is mapped to a new image through a filter kernel, as described in Eq.~\ref{eqn:kernel}.
The filter kernel is a fixed dimensions sub-image with a weighting on each pixel that is applied to each voxel in the image which is convolution.
If filter kernel contains all ones is known as \emph{box filter} and performs smoothing on the image to remove noise.
A Gaussian filter performs better by placing a higher weighting on the central voxel and less on the extreme voxels~\cite{lohmann1998volumetric}.


\begin{equation}
	I'(u,v,w) = \sum\limits_{(i,j,k) \in R_H} I(u + i,v + j, w + k)H(i,j,k)
	\label{eqn:kernel} 
\end{equation}



\subsection{Frequency Filtering}
The Fourier transform, as used spatially on 2D images, can be extended to 3D images.
A Discrete Fourier Transform (DFT) for a $N$$\times$$N$$\times$$N$ voxel image is held in Eq.~\ref{eqn:dft}.
The spatial filtering process performs convolution so once an image is in the frequency domain the same effects can be achieved using multiplication.
It may prove more efficient to filter an image in frequency rather than space if the required filter kernel is large.
Band-pass filter operations can also be perform in the frequency domain.

\begin{equation}
	\textbf{FP}_{u,v,w} = \frac{1}{N^{\frac{3}{2}}} \sum\limits_{x=-\frac{N}{2}}^{\frac{N}{2}-1}\sum\limits_{y=-\frac{N}{2}}^{\frac{N}{2}-1}\sum\limits_{z=-\frac{N}{2}}^{\frac{N}{2}-1}\textbf{P}_{x,y,z}e^{-j\frac{2\pi}{N}(ux + vy + wz)}
	\label{eqn:dft} 
\end{equation}










\section{Feature Selection}
\label{sec:selection}
Before features can be extracted from a image it must be clear what features will be useful to a classification algorithm.
Reducing dimensionality through feature reduction can often prove more effective then lower dimensional projection methods; discussed in Section~\ref{sec:reduce}.
The recommendation of feature selection can come from domain knowledge or convergence on a subset that will provided a sufficiently low training error using an iterative tuning algorithm~\cite{bu07feature,li10tumor}.
A combination of both suits this purpose where domain knowledge may over recommend features and a machine learning approach can prune as required for the subset.  










\section{Feature Extraction}
\label{sec:extraction}











\section{Dimensionaility Reduction}
\label{sec:reduce}











\section{Classification}
\label{sec:class}









\section{Conclusions}
\label{sec:conclusions}

It is clear that this tool can't be used as a hard and fast method of tumor diagnosis but instead as a valuable tool for image reviewers.
Software packages designed for medical image review, such as~\cite{slicer}, have bidirectional interfaces to custom extensions.
Implementing this system as an extension would remove many overheads required in data handling but reduce the scope for optimisation.
The feedback from the entire process would be a checklist which the user must manually review and waive if incorrectly identified. 










\bibliographystyle{ieeetran}
\bibliography{references}

\end{document}


